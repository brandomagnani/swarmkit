{
  "title": "On Learning to Think: Algorithmic Information Theory (2015)",
  "summary": "This HN post (rank 22, 155 points) linked to J\u00fcrgen Schmidhuber's arXiv paper 'On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models.' The paper proposed RNN-based AI systems that learn predictive models of their environment and use them for abstract reasoning and planning. The discussion was minimal (3 comments), with sevensor noting that neural networks were obviously the hot thing in AI and praising the paper's literature review. The other comments were brief tangential remarks about the author and appearance of related videos.",
  "what_happened": "Schmidhuber's 2015 ideas on world models and learning to think proved to be foundational and highly prescient. In 2018, David Ha and Schmidhuber co-authored the influential 'World Models' paper (arXiv:1803.10122) which formalized and expanded on these concepts. World models have since become a major area of AI research, with widespread applications by 2024 in reinforcement learning, embodied AI, video/text generation, and multimodal scenarios. The concepts directly influenced the modern approach to combining RL with world models for abstract reasoning. Algorithmic information theory, while niche in 2015, has gained relevance as researchers seek stronger theoretical foundations for machine learning algorithms. By 2024-2025, world models and RL are being actively combined with large language models for reasoning tasks, and AIT is being actively integrated with modern ML approaches.",
  "most_prescient": {
    "user": "sevensor",
    "reason": "Correctly identified that neural networks were 'obviously the hot thing in AI' in 2015, which proved prescient as deep learning and neural approaches dominated the next decade. Also accurately assessed that the paper had 'a great lit review,' reflecting good judgment about the work's quality and positioning. The comment, while brief, demonstrated sound understanding of AI trends that unfolded exactly as predicted."
  },
  "most_wrong": {
    "user": "N/A",
    "reason": "The discussion was too minimal to identify meaningfully wrong predictions. The only substantive comment (sevensor) was accurate. The other comments (tlarkworthy, skosuri) were trivial tangential remarks about the author and appearance, not predictions about the technology or its impact."
  },
  "notable_aspects": "This is a fascinating retrospective because the original discussion was remarkably sparse for a paper that would prove so influential. The HN community engaged very little with this work in 2015, despite it containing ideas that would become central to AI research within 3-5 years. The 'World Models' follow-up paper in 2018 received far more attention and citations, suggesting the original 2015 formulation was perhaps ahead of the curve or not yet accessible to the broader ML community. Schmidhuber's decades-long research on world models (1990-2015) also highlights how important foundational work can take decades to gain mainstream recognition.",
  "grades": {
    "sevensor": {
      "grade": "A+",
      "rationale": "Correctly identified the dominance of neural networks in AI and accurately assessed the paper's quality. Demonstrated good judgment about both the technical trends and the work's merits, with zero inaccuracy."
    },
    "tlarkworthy": {
      "grade": "N/A",
      "rationale": "Comment was too brief and tangential ('And author') to evaluate substantively."
    },
    "skosuri": {
      "grade": "N/A",
      "rationale": "Comment was off-topic (remarking on video appearance) rather than engaging with the technical content or making predictions about AI development."
    }
  },
  "score": 8
}